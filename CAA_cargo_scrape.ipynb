{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b7d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests for downloading things off the internet, in this case the CSV files\n",
    "# pandas we know is good for handling data (could do all this without it but just makes things easier)\n",
    "# re is the 'regular expression' library which is a bit complicated\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# we need somewhere to store our collection of data so create an empty data frame to start\n",
    "big_df = pd.DataFrame()\n",
    "\n",
    "# create a loop which will go year-by-year for these years\n",
    "for year in [2018,2019,2020]:\n",
    "    # for each year we need to get each month (note Python is *exclusive* here hence 1-13)\n",
    "    for month in range(1,13):\n",
    "        # download the page of links to tables for each month of each year published on CAA website\n",
    "        stub = \"https://www.caa.co.uk/Data-and-analysis/UK-aviation-market/Airports/Datasets/UK-Airport-data/\"\n",
    "        # handle the fact that the pages for Jan to Sep include a 0 in the address i.e. the month is padded\n",
    "        if month < 10:\n",
    "            padded_month = \"0\" + str(month)\n",
    "        else:\n",
    "            padded_month = str(month)\n",
    "        target = \"Airport-data-\" + str(year) + \"-\" + padded_month + \"/\"\n",
    "        url = stub + target\n",
    "        # print the URL on the screen to show each page we are going to download (helps with spotting any problems)\n",
    "        print(url)\n",
    "        # now let's download this page\n",
    "        html = requests.get(url).text\n",
    "        # this gives us a big block of HTML, hiding in it is the link to the CSV file we want to get\n",
    "        # first split the big block into individual lines \"\\n\" here means end of line\n",
    "        for line in html.split(\"\\n\"):\n",
    "            # this is where we use 'regular expressions' which are a bit complicated\n",
    "            # an added complication is that for some reason the October file for one year is in a different place!?\n",
    "            # the next two lines of code basically find the link to the Table_13.csv file that we want to get\n",
    "            p = 'uploadedFiles\\/CAA\\/Content\\/Standard_Content\\/Data_and_analysis\\/Datasets\\/Airport_stats\\/[Airport_data_20.._..|October][^\\/]*\\/Table_13[^\\.]*.csv'\n",
    "            href = re.search(p, line, flags=re.I)\n",
    "            # this block of code is what happens when we have found the link\n",
    "            if href:\n",
    "                # print the link on the screen to show us what we are trying to download\n",
    "                print(href.group())\n",
    "                # download this CSV file into a pandas dataframe using pd.read_csv\n",
    "                df = pd.read_csv('https://www.caa.co.uk/' + href.group())\n",
    "                # is our big dataframe empty? if so we can just copy across this data straight into it\n",
    "                if big_df.empty:\n",
    "                    big_df = df.copy()\n",
    "                # if big dataframe is *not* empty we don't want to accidentally overwrite the data already in it!!\n",
    "                # so *append* the new data to the end of the big dataframe instead\n",
    "                else:\n",
    "                    big_df = big_df.append(df)\n",
    "\n",
    "# finished!\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a536494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our data to a new CSV file\n",
    "# pandas adds an 'index' column that we do not want, using index=False throws it away\n",
    "big_df.to_csv('cargo_2018-2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f6853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-use above code to get Table 09 instead\n",
    "big_df = pd.DataFrame()\n",
    "for year in [2018,2019,2020]:\n",
    "    for month in range(1,13):\n",
    "        #print(year, month)\n",
    "        stub = \"https://www.caa.co.uk/Data-and-analysis/UK-aviation-market/Airports/Datasets/UK-Airport-data/\"\n",
    "        target = f\"Airport-data-{year}-0{month}/\" if month < 10 else f\"Airport-data-{year}-{month}/\"\n",
    "        url = stub + target\n",
    "        print(url)\n",
    "        html = requests.get(url).text\n",
    "        #print(html)\n",
    "        for line in html.split(\"\\n\"):\n",
    "            #print(line)\n",
    "            p = '\\/uploadedFiles\\/CAA\\/Content\\/Standard_Content\\/Data_and_analysis\\/Datasets\\/Airport_stats\\/[Airport_data_20.._..|October][^\\/]*\\/Table_09[^\\.]*.csv'\n",
    "            href = re.search(p, line, flags=re.I)\n",
    "            if href:\n",
    "                print(href.group())\n",
    "                df = pd.read_csv('https://www.caa.co.uk' + href.group())\n",
    "                if big_df.empty:\n",
    "                    big_df = df.copy()\n",
    "                else:\n",
    "                    big_df = big_df.append(df)\n",
    "                break\n",
    "print(\"Done!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdebe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a new CSV file\n",
    "big_df.to_csv('pax_2018-2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b0af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
